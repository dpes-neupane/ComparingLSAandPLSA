{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import preprocessing\n",
    "import os \n",
    "\n",
    "# don't forget to change the '/' in the filename to '\\\\' in windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dirs = os.listdir(\"./16NepaliNews/raw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no need to run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories(folder): # no need to run this now\n",
    "    for dir in dirs:\n",
    "        os.makedirs(os.path.join(folder,dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(dir, filename, text):\n",
    "    folder_name = \"Preprocessed\"\n",
    "    path = \".\\\\\" + os.path.join(folder_name, dir, filename )\n",
    "    \n",
    "    with open(path, \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepali_stemmer.stemmer import NepStemmer\n",
    "\n",
    "\n",
    "def preProcess(folder_start, folder_end):\n",
    "    punc = preprocessing.Preprocessing()\n",
    "    #running the simple preprocessing for all files\n",
    "    for folder in dirs[folder_start: folder_end]: \n",
    "        dir = os.getcwd() + \"/16NepaliNews/raw/\" + folder\n",
    "        print(folder)\n",
    "        for file in os.listdir(dir): #remove the list value [:1]\n",
    "            filename = dir + \"/\" + file\n",
    "            \n",
    "            \n",
    "            \n",
    "            text = punc.delPnctuatn(filename=filename, next=True)\n",
    "            \n",
    "            \n",
    "            text = punc.delEngWords(text=text, next=True)\n",
    "            \n",
    "            \n",
    "            text = punc.delNumbers(text=text, next=True)\n",
    "            \n",
    "            text = punc.delStopwords(text=text, next=True)\n",
    "            \n",
    "            stem = NepStemmer()\n",
    "            text = stem.stem(text)\n",
    "            write_file(folder, file, text)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_extraction import tfidfvectorizer\n",
    "\n",
    "counter = tfidfvectorizer.TfidfVectorizer()\n",
    "# counter.vocabulary(path=\".\\\\Preprocessed\\\\Technology\\\\04_11_21_10_39_40.txt\")\n",
    "# counter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business\n",
      "1408\n",
      "Education\n",
      "1296\n",
      "Entertainment\n",
      "1309\n",
      "Health\n",
      "1301\n",
      "Interview\n",
      "1383\n",
      "Literature\n",
      "1237\n",
      "NationalNews\n",
      "1440\n",
      "Opinion\n",
      "1321\n",
      "Sports\n",
      "1295\n",
      "Technology\n",
      "1372\n",
      "Tourism\n",
      "1380\n",
      "World\n",
      "1366\n"
     ]
    }
   ],
   "source": [
    "def count_words():\n",
    "    for folder in dirs:\n",
    "        dir = os.getcwd() + \"\\\\FilteredPreprocessed\\\\\" + folder\n",
    "        print(folder)\n",
    "        count = 0\n",
    "        \n",
    "        for file in os.listdir(dir):\n",
    "            filename = dir +\"\\\\\" + file\n",
    "            counter.vocabulary(path=filename)\n",
    "            count+=1\n",
    "        print(count)\n",
    "count_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169205"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(1000):\n",
    "#     print(counter.vocab[list(counter.vocab.keys())[i]], list(counter.vocab.keys())[i])\n",
    "    \n",
    "len(counter.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".\\\\vocab.txt\",\"w\", encoding=\"utf-8\") as fp:\n",
    "    for key in counter.vocab.keys():\n",
    "        fp.write(key + \" \" + str(counter.vocab[key])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e19f2ee28a2596421b32a582284268244e387339577b4a62b40e9936a7c1aa89"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
