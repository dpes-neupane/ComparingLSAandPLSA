{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_preprocessing import preprocessing\n",
    "import os \n",
    "\n",
    "# don't forget to change the '/' in the filename to '\\\\' in windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dirs = os.listdir(\"./16NepaliNews/raw\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no need to run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_directories(folder): # no need to run this now\n",
    "    for dir in dirs:\n",
    "        os.makedirs(os.path.join(folder,dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(dir, filename, text):\n",
    "    folder_name = \"Preprocessed\"\n",
    "    path = \".\\\\\" + os.path.join(folder_name, dir, filename )\n",
    "    \n",
    "    with open(path, \"w\", encoding=\"utf-8\") as fp:\n",
    "        fp.write(text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nepali_stemmer.stemmer import NepStemmer\n",
    "\n",
    "\n",
    "def preProcess(folder_start, folder_end):\n",
    "    punc = preprocessing.Preprocessing()\n",
    "    #running the simple preprocessing for all files\n",
    "    for folder in dirs[folder_start: folder_end]: \n",
    "        dir = os.getcwd() + \"/16NepaliNews/raw/\" + folder\n",
    "        print(folder)\n",
    "        for file in os.listdir(dir): #remove the list value [:1]\n",
    "            filename = dir + \"/\" + file\n",
    "            \n",
    "            \n",
    "            \n",
    "            text = punc.delPnctuatn(filename=filename, next=True)\n",
    "            \n",
    "            \n",
    "            text = punc.delEngWords(text=text, next=True)\n",
    "            \n",
    "            \n",
    "            text = punc.delNumbers(text=text, next=True)\n",
    "            \n",
    "            text = punc.delStopwords(text=text, next=True)\n",
    "            \n",
    "            stem = NepStemmer()\n",
    "            text = stem.stem(text)\n",
    "            write_file(folder, file, text)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'काठमाडौं': [1, 0],\n",
       " 'विगत': [1, 0],\n",
       " 'समय': [3, 0],\n",
       " 'नेपाल': [3, 0],\n",
       " 'टेलिकम': [10, 0],\n",
       " 'मोबाइल': [7, 0],\n",
       " 'नम्बर': [1, 0],\n",
       " 'विदेश': [1, 0],\n",
       " 'मिस्ड': [2, 0],\n",
       " 'कल': [9, 0],\n",
       " 'आउने': [1, 0],\n",
       " 'व्याक': [1, 0],\n",
       " 'गर्दा': [2, 0],\n",
       " 'नबोल्ने': [1, 0],\n",
       " 'मेसिन': [1, 0],\n",
       " 'जवाफ': [1, 0],\n",
       " 'फर्काउने': [1, 0],\n",
       " 'समस्या': [2, 0],\n",
       " 'देखिए': [2, 0],\n",
       " 'खोजी': [3, 0],\n",
       " 'कतिपय': [1, 0],\n",
       " 'ग्राहक': [6, 0],\n",
       " 'देखिने': [1, 0],\n",
       " 'ब्याक': [1, 0],\n",
       " 'नबो': [1, 0],\n",
       " 'पैसा': [2, 0],\n",
       " 'काटिने': [2, 0],\n",
       " 'गुनासो': [1, 0],\n",
       " 'आए': [1, 0],\n",
       " 'यस्ता': [4, 0],\n",
       " 'घटना': [1, 0],\n",
       " 'सम्भवतः': [2, 0],\n",
       " 'एप': [3, 0],\n",
       " 'वेबसाइट': [2, 0],\n",
       " 'माध्यम': [1, 0],\n",
       " 'हुनसक्ने': [3, 0],\n",
       " 'तर्फ': [2, 0],\n",
       " 'सचेत': [1, 0],\n",
       " 'गराए': [1, 0],\n",
       " 'सेट': [1, 0],\n",
       " 'अनावश्यक': [2, 0],\n",
       " 'शंकास्पद': [1, 0],\n",
       " 'इन्स्टल': [1, 0],\n",
       " 'नगर्न': [1, 0],\n",
       " 'हटाउन': [1, 0],\n",
       " 'अनुरोध': [1, 0],\n",
       " 'सामान्यतया': [1, 0],\n",
       " 'कम्पनी': [4, 0],\n",
       " 'उपकरण': [1, 0],\n",
       " 'अनधिकृत': [3, 0],\n",
       " 'नहुने': [2, 0],\n",
       " 'भएता': [1, 0],\n",
       " 'ग्राहकवर्ग': [1, 0],\n",
       " 'सुविधा': [1, 0],\n",
       " 'मार्फत': [1, 0],\n",
       " 'कार्य': [1, 0],\n",
       " 'सम्बन्ध': [1, 0],\n",
       " 'आवश्यक': [3, 0],\n",
       " 'भइ': [1, 0],\n",
       " 'जनाए': [2, 0],\n",
       " 'त्यसैगरी': [1, 0],\n",
       " 'दिन': [1, 0],\n",
       " 'यता': [1, 0],\n",
       " 'सेवा': [3, 0],\n",
       " 'अटो': [2, 0],\n",
       " 'डायल': [2, 0],\n",
       " 'भए': [1, 0],\n",
       " 'लग': [1, 0],\n",
       " 'नदेखिने': [1, 0],\n",
       " 'बाह्य': [1, 0],\n",
       " 'सफल': [1, 0],\n",
       " 'अवस्था': [3, 0],\n",
       " 'जस्ता': [1, 0],\n",
       " 'पाइए': [1, 0],\n",
       " 'बच्न': [1, 0],\n",
       " 'सतर्क': [1, 0],\n",
       " 'रहन': [1, 0],\n",
       " 'आग्रह': [2, 0],\n",
       " 'उपलब्ध': [1, 0],\n",
       " 'गराउने': [1, 0],\n",
       " 'लकिङ': [1, 0],\n",
       " 'कोड': [1, 0],\n",
       " 'प्रयोग': [1, 0],\n",
       " 'परे': [1, 0],\n",
       " 'आइएसडी': [1, 0],\n",
       " 'खोली': [1, 0],\n",
       " 'पुनः': [1, 0],\n",
       " 'बन्द': [1, 0],\n",
       " 'सकिने': [1, 0],\n",
       " 'विकल्प': [1, 0],\n",
       " 'उपयोग': [1, 0]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.feature_extraction import tfidfvectorizer\n",
    "\n",
    "counter = tfidfvectorizer.TfidfVectorizer()\n",
    "counter.vocabulary(path=\".\\\\Preprocessed\\\\Technology\\\\04_11_21_10_39_40.txt\")\n",
    "counter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business\n",
      "2875\n",
      "Education\n",
      "2629\n",
      "Entertainment\n",
      "2639\n",
      "Health\n",
      "2619\n",
      "Interview\n",
      "2772\n",
      "Literature\n",
      "2479\n",
      "NationalNews\n",
      "2902\n",
      "Opinion\n",
      "2648\n",
      "Sports\n",
      "2655\n",
      "Technology\n",
      "2754\n",
      "Tourism\n",
      "2778\n",
      "World\n",
      "2765\n"
     ]
    }
   ],
   "source": [
    "def count_words():\n",
    "    for folder in dirs:\n",
    "        dir = os.getcwd() + \"\\\\Preprocessed\\\\\" + folder\n",
    "        print(folder)\n",
    "        count = 0\n",
    "        \n",
    "        for file in os.listdir(dir):\n",
    "            filename = dir +\"\\\\\" + file\n",
    "            counter.vocabulary(path=filename)\n",
    "            count+=1\n",
    "        print(count)\n",
    "count_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308294"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for i in range(1000):\n",
    "#     print(counter.vocab[list(counter.vocab.keys())[i]], list(counter.vocab.keys())[i])\n",
    "    \n",
    "len(counter.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\".\\\\vocab.txt\",\"w\", encoding=\"utf-8\") as fp:\n",
    "    for key in counter.vocab.keys():\n",
    "        fp.write(key + \" \" + str(counter.vocab[key])+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Business': [1, 2875],\n",
       " 'Education': [2876, 5504],\n",
       " 'Entertainment': [5505, 8143],\n",
       " 'Health': [8144, 10762],\n",
       " 'Interview': [10763, 13534],\n",
       " 'Literature': [13535, 16013],\n",
       " 'NationalNews': [16014, 18915],\n",
       " 'Opinion': [18916, 21563],\n",
       " 'Sports': [21564, 24218],\n",
       " 'Technology': [24219, 26972],\n",
       " 'Tourism': [26973, 29750],\n",
       " 'World': [29751, 32515]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.feature_extraction import tfidfvectorizer\n",
    "vectorizer = tfidfvectorizer.TfidfVectorizer()\n",
    "vectorizer.label(root='./Preprocessed/')\n",
    "vectorizer.label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./Preprocessed\\\\Business', './Preprocessed\\\\Education', './Preprocessed\\\\Entertainment', './Preprocessed\\\\Health', './Preprocessed\\\\Interview', './Preprocessed\\\\Literature', './Preprocessed\\\\NationalNews', './Preprocessed\\\\Opinion', './Preprocessed\\\\Sports', './Preprocessed\\\\Technology', './Preprocessed\\\\Tourism', './Preprocessed\\\\World']\n",
      "2661 left of 2875 of Business\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32me:\\Project\\NewsTextClassifierSeventhProject\\machinelearningmodel.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Project/NewsTextClassifierSeventhProject/machinelearningmodel.ipynb#ch0000011?line=0'>1</a>\u001b[0m vectorizer\u001b[39m.\u001b[39;49mdocumentTermMat(Path\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./Preprocessed\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Project/NewsTextClassifierSeventhProject/machinelearningmodel.ipynb#ch0000011?line=1'>2</a>\u001b[0m vectorizer\u001b[39m.\u001b[39mvec\n",
      "File \u001b[1;32me:\\Project\\NewsTextClassifierSeventhProject\\src\\feature_extraction\\tfidfvectorizer.py:152\u001b[0m, in \u001b[0;36mTfidfVectorizer.documentTermMat\u001b[1;34m(self, Path, input_text)\u001b[0m\n\u001b[0;32m    <a href='file:///e%3A/Project/NewsTextClassifierSeventhProject/src/feature_extraction/tfidfvectorizer.py?line=149'>150</a>\u001b[0m             row\u001b[39m.\u001b[39mappend(cnt[wordlist[x]])\n\u001b[0;32m    <a href='file:///e%3A/Project/NewsTextClassifierSeventhProject/src/feature_extraction/tfidfvectorizer.py?line=150'>151</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///e%3A/Project/NewsTextClassifierSeventhProject/src/feature_extraction/tfidfvectorizer.py?line=151'>152</a>\u001b[0m             row\u001b[39m.\u001b[39;49mappend(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    <a href='file:///e%3A/Project/NewsTextClassifierSeventhProject/src/feature_extraction/tfidfvectorizer.py?line=152'>153</a>\u001b[0m hfcyvy \u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///e%3A/Project/NewsTextClassifierSeventhProject/src/feature_extraction/tfidfvectorizer.py?line=153'>154</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00misnumber\u001b[39m}\u001b[39;00m\u001b[39m left of \u001b[39m\u001b[39m{\u001b[39;00misnumbertotal\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mdirs[i]\u001b[39m.\u001b[39msplit(hfcyvy)[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer.documentTermMat(Path=\"./Preprocessed\")\n",
    "vectorizer.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e19f2ee28a2596421b32a582284268244e387339577b4a62b40e9936a7c1aa89"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
